{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Choice Models\n",
    "In a typical linear regression model, we assume that the dependent variable is either continuous or binary. \n",
    "y_it=Œ≤_0+Œ≤_1 x_1it+Œ≤_2 x_2it+Œ≤_3 x_3it+Œª_t+œµ_it\n",
    "An example of a continuous dependent variable might be the height of a tomato plant in inches. In this model, y_it is the height of the i^th tomato plant at time t, as a function of an intercept term, the amount of water (x_1), sunlight (x_2) and fertilizer (x_3) the plant receives, and a time trend variable. We interpret each coefficient Œ≤ as the slope between its corresponding x and the value of y, holding all other independent variables constant.\n",
    "An example of a binary dependent variable might be whether an individual attends college. In this model, y_it=1 corresponds to attending college for at least one semester, and y_it=0 corresponds to never attending college. We‚Äôd include an intercept term, and we‚Äôd also consider including covariates (independent variables) like family income (x_1), whether a parent attended college (x_2), high school GPA (x_3), and a time trend. We interpret each coefficient Œ≤ as an increase or decrease to the probability of observing y = 1 for the dependent variable.\n",
    "Both models are easy to estimate using linear regression models (such as OLS). But what happens when the choice faced by an individual doesn‚Äôt correspond to a binary outcome (for example, college/no college), but to multiple options from a categorical variable (for example, Apple iPhone / Android / Samsung Galaxy)? \n",
    "Multinomial choice models are used to provide mathematical structure to these problems. As with linear regression models, our goal is to estimate the parameters (coefficients) Œ≤ that correspond to the covariates of interest x that we expect will influence the outcome. The output of the model is a set of probabilities that a given agent will choose one option compared to another. \n",
    "Multinomial choice models are used in practically every field of study. Brainstorm (or research) some applications of multinomial choice models in your chosen area (whether it‚Äôs your major, your anticipated career path, or just a field you find interesting). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Head:\n",
      "    id  time_Bike  time_Bus  time_Car  cost_Bike  cost_Bus  cost_Car  \\\n",
      "0   1    19.4296   30.4610   32.4836          0    1.5683    6.3994   \n",
      "1   2    21.8453   35.6981   29.3087          0    1.9844    5.9246   \n",
      "2   3    20.2897   37.9320   33.2384          0    2.0090    5.0596   \n",
      "3   4    22.2600   49.4384   37.6151          0    2.2363    4.3531   \n",
      "4   5    23.9292   42.7828   28.8292          0    1.3166    5.6982   \n",
      "\n",
      "   risk_Bike  risk_Bus  risk_Car choice  choice_code  Unnamed: 12  Unnamed: 13  \n",
      "0     0.0379    0.0087    0.0166    Car            2          NaN          NaN  \n",
      "1     0.0122    0.0086    0.0193    Car            2          NaN          NaN  \n",
      "2     0.0371    0.0046    0.0160    Bus            1          NaN          NaN  \n",
      "3     0.0277    0.0090    0.0185   Bike            0          NaN          NaN  \n",
      "4     0.0371    0.0122    0.0105    Bus            1          NaN          NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           1000 non-null   int64  \n",
      " 1   time_Bike    1000 non-null   float64\n",
      " 2   time_Bus     1000 non-null   float64\n",
      " 3   time_Car     1000 non-null   float64\n",
      " 4   cost_Bike    1000 non-null   int64  \n",
      " 5   cost_Bus     1000 non-null   float64\n",
      " 6   cost_Car     1000 non-null   float64\n",
      " 7   risk_Bike    1000 non-null   float64\n",
      " 8   risk_Bus     1000 non-null   float64\n",
      " 9   risk_Car     1000 non-null   float64\n",
      " 10  choice       1000 non-null   object \n",
      " 11  choice_code  1000 non-null   int64  \n",
      " 12  Unnamed: 12  0 non-null      float64\n",
      " 13  Unnamed: 13  0 non-null      float64\n",
      "dtypes: float64(10), int64(3), object(1)\n",
      "memory usage: 109.5+ KB\n",
      "\n",
      "Column Info:\n",
      " None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Transport_Mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\snehal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Transport_Mode'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Head:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mColumn Info:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39minfo())\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClass Distribution:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransport_Mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Assume 'Transport_Mode' is the categorical target variable\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# and other columns are features\u001b[39;00m\n\u001b[0;32m     18\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransport_Mode\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\snehal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\snehal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Transport_Mode'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"D:\\BINGHAMTON University\\Spring Semester 2025\\DATA 580E_E- Numeric Methods for Optimization\\transportation_ml.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset Head:\\n\", df.head())\n",
    "print(\"\\nColumn Info:\\n\", df.info())\n",
    "print(\"\\nClass Distribution:\\n\", df['Transport_Mode'].value_counts())\n",
    "\n",
    "# Assume 'Transport_Mode' is the categorical target variable\n",
    "# and other columns are features\n",
    "target = 'Transport_Mode'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Optional: encode categorical variables if needed\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a multinomial logistic regression\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "œÄ_A / œÄ_B with all 3 choices   = 0.6126\n",
      "œÄ_A / œÄ_B with only A and B    = 0.6126\n",
      "‚úÖ Ratios equal (IIA holds)?    = True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulated covariates (x_ij) for one individual and three alternatives (j = A, B, C)\n",
    "x_A = np.array([1.0, 2.0])   # features for alternative A\n",
    "x_B = np.array([1.5, 1.2])   # features for alternative B\n",
    "x_C = np.array([0.8, 1.6])   # features for alternative C\n",
    "\n",
    "# Coefficients Œ≤\n",
    "beta = np.array([0.5, -0.3])\n",
    "\n",
    "# Compute linear utility x_ij * beta\n",
    "u_A = x_A @ beta\n",
    "u_B = x_B @ beta\n",
    "u_C = x_C @ beta\n",
    "\n",
    "# Compute exp(x_ij * beta)\n",
    "exp_A = np.exp(u_A)\n",
    "exp_B = np.exp(u_B)\n",
    "exp_C = np.exp(u_C)\n",
    "\n",
    "# With all 3 alternatives\n",
    "denominator_full = exp_A + exp_B + exp_C\n",
    "pi_A_full = exp_A / denominator_full\n",
    "pi_B_full = exp_B / denominator_full\n",
    "\n",
    "# With only 2 alternatives: A and B (remove C)\n",
    "denominator_AB = exp_A + exp_B\n",
    "pi_A_ab = exp_A / denominator_AB\n",
    "pi_B_ab = exp_B / denominator_AB\n",
    "\n",
    "# Compare the ratios\n",
    "odds_full = pi_A_full / pi_B_full\n",
    "odds_ab = pi_A_ab / pi_B_ab\n",
    "\n",
    "# Show that the ratio stays the same\n",
    "print(\"œÄ_A / œÄ_B with all 3 choices   =\", round(odds_full, 4))\n",
    "print(\"œÄ_A / œÄ_B with only A and B    =\", round(odds_ab, 4))\n",
    "print(\"‚úÖ Ratios equal (IIA holds)?    =\", np.isclose(odds_full, odds_ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \tCan you prove algebraically that the relative probabilities of two choices do not depend on the presence or absence of other choices? (Hint: use the equation above, and find the ratio œÄ_ij/œÄ_ik for j‚â†k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds (Alt1 vs Alt2) with 3 choices: 0.9418\n",
      "Odds (Alt1 vs Alt2) with 2 choices: 0.9418\n",
      "Are odds equal? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Simulated Œ≤ coefficients for 3 features\n",
    "beta = np.array([0.5, -0.3, 0.2])\n",
    "\n",
    "# Simulate covariates x_ij for 1 agent (i=1) and 3 alternatives (j=1,2,3)\n",
    "x = {\n",
    "    'Alt1': np.array([1.0, 2.0, 1.5]),\n",
    "    'Alt2': np.array([1.2, 1.8, 1.0]),\n",
    "    'Alt3': np.array([0.8, 2.2, 1.3])\n",
    "}\n",
    "\n",
    "# Compute utility and exp(xŒ≤) for each alternative\n",
    "utilities = {alt: x[alt] @ beta for alt in x}\n",
    "exp_utilities = {alt: np.exp(utilities[alt]) for alt in x}\n",
    "\n",
    "# Full choice set: Alt1, Alt2, Alt3\n",
    "denominator_full = sum(exp_utilities.values())\n",
    "prob_full = {alt: exp_utilities[alt] / denominator_full for alt in x}\n",
    "\n",
    "# Subset choice set: Alt1, Alt2 only\n",
    "denominator_subset = exp_utilities['Alt1'] + exp_utilities['Alt2']\n",
    "prob_subset = {\n",
    "    'Alt1': exp_utilities['Alt1'] / denominator_subset,\n",
    "    'Alt2': exp_utilities['Alt2'] / denominator_subset\n",
    "}\n",
    "\n",
    "# Compute relative odds\n",
    "odds_full = prob_full['Alt1'] / prob_full['Alt2']\n",
    "odds_subset = prob_subset['Alt1'] / prob_subset['Alt2']\n",
    "\n",
    "print(\"Odds (Alt1 vs Alt2) with 3 choices:\", round(odds_full, 4))\n",
    "print(\"Odds (Alt1 vs Alt2) with 2 choices:\", round(odds_subset, 4))\n",
    "print(\"Are odds equal?\", np.isclose(odds_full, odds_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä First-Past-the-Post Results:\n",
      "1st\n",
      "B    0.40\n",
      "C    0.35\n",
      "A    0.25\n",
      "Name: percent, dtype: float64\n",
      "\n",
      "üèÜ Winner (FPTP): B\n",
      "\n",
      "üßÆ Top Two Candidates for Runoff: ['B', 'C']\n",
      "\n",
      "üìä Runoff Results:\n",
      "runoff_vote\n",
      "B    0.65\n",
      "C    0.35\n",
      "Name: percent, dtype: float64\n",
      "\n",
      "üèÜ Winner (Runoff): B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define voter groups and their rankings\n",
    "voters = pd.DataFrame({\n",
    "    'group': ['G1', 'G2', 'G3'],\n",
    "    'percent': [0.25, 0.40, 0.35],\n",
    "    '1st': ['A', 'B', 'C'],\n",
    "    '2nd': ['B', 'C', 'A'],\n",
    "    '3rd': ['C', 'A', 'B']\n",
    "})\n",
    "\n",
    "# First-past-the-post: count only first-choice votes\n",
    "fptp_results = voters.groupby('1st')['percent'].sum().sort_values(ascending=False)\n",
    "print(\"üìä First-Past-the-Post Results:\")\n",
    "print(fptp_results)\n",
    "print(f\"\\nüèÜ Winner (FPTP): {fptp_results.idxmax()}\")\n",
    "\n",
    "# Top-two runoff\n",
    "# Step 1: Identify top two from first round (same as FPTP)\n",
    "top_two = fptp_results.index[:2].tolist()\n",
    "print(f\"\\nüßÆ Top Two Candidates for Runoff: {top_two}\")\n",
    "\n",
    "# Step 2: Redistribute votes in runoff between top two\n",
    "def runoff_vote(row, top_two):\n",
    "    # Go through preferences in order\n",
    "    for col in ['1st', '2nd', '3rd']:\n",
    "        if row[col] in top_two:\n",
    "            return row[col]\n",
    "    return None\n",
    "\n",
    "voters['runoff_vote'] = voters.apply(lambda row: runoff_vote(row, top_two), axis=1)\n",
    "\n",
    "runoff_results = voters.groupby('runoff_vote')['percent'].sum()\n",
    "print(\"\\nüìä Runoff Results:\")\n",
    "print(runoff_results)\n",
    "print(f\"\\nüèÜ Winner (Runoff): {runoff_results.idxmax()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. \tSet up and estimate a multinomial logit model to identify maximum-likelihood estimates of the parameter values Œ≤_time, Œ≤_cost, and Œ≤_risk. Identify which of these coefficients are statistically significant, if any, and interpret your findings. Note that, for technical reasons, you may have to transform the data by specifying one of the modes of transportation (‚Äúalternatives‚Äù) as the ‚Äúpivot‚Äù or ‚Äúreference‚Äù mode, and recoding the other variables as differences from the value corresponding to that ‚Äúpivot‚Äù alternative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.626882\n",
      "         Iterations 5\n",
      "\n",
      "üìä Model Summary:\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 chosen   No. Observations:                 3000\n",
      "Model:                        MNLogit   Df Residuals:                     2994\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Fri, 28 Mar 2025   Pseudo R-squ.:                 0.01513\n",
      "Time:                        21:31:41   Log-Likelihood:                -1880.6\n",
      "converged:                       True   LL-Null:                       -1909.5\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.466e-11\n",
      "==============================================================================\n",
      "  chosen=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.0212      0.265      3.848      0.000       0.501       1.541\n",
      "time          -0.0458      0.008     -5.830      0.000      -0.061      -0.030\n",
      "cost          -0.1132      0.062     -1.813      0.070      -0.236       0.009\n",
      "risk         -14.5220      5.671     -2.561      0.010     -25.638      -3.406\n",
      "mode_bus       0.5085      0.226      2.253      0.024       0.066       0.951\n",
      "mode_car       0.3173      0.336      0.944      0.345      -0.341       0.976\n",
      "==============================================================================\n",
      "\n",
      "üîÅ Odds Ratios (exp(coefficients)):\n",
      "                     0\n",
      "const     2.776660e+00\n",
      "time      9.552530e-01\n",
      "cost      8.929406e-01\n",
      "risk      4.933897e-07\n",
      "mode_bus  1.662725e+00\n",
      "mode_car  1.373389e+00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Step 1: Load and clean the dataset\n",
    "file_path = \"transportation_ml.csv\"  # path to your local file in VS Code project\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column names and remove unnecessary ones\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^unnamed\")]\n",
    "\n",
    "# Step 2: Transform wide to long format\n",
    "long_df = pd.wide_to_long(df,\n",
    "                          stubnames=['time', 'cost', 'risk'],\n",
    "                          i='id',\n",
    "                          j='mode',\n",
    "                          sep='_',\n",
    "                          suffix='.+').reset_index()\n",
    "\n",
    "# Step 3: Prepare 'choice' and 'mode' columns\n",
    "df['choice'] = df['choice'].astype(str).str.strip().str.lower()\n",
    "long_df['mode'] = long_df['mode'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Merge 'choice' column into long_df\n",
    "long_df = long_df.merge(df[['id', 'choice']], on='id', how='left')\n",
    "\n",
    "# Fix potential renaming during merge\n",
    "if 'choice_y' in long_df.columns:\n",
    "    long_df.rename(columns={'choice_y': 'choice'}, inplace=True)\n",
    "elif 'choice_x' in long_df.columns:\n",
    "    long_df.rename(columns={'choice_x': 'choice'}, inplace=True)\n",
    "\n",
    "# Step 4: Create binary outcome for the chosen alternative\n",
    "long_df['chosen'] = (long_df['mode'] == long_df['choice']).astype(int)\n",
    "\n",
    "# Step 5: Create dummy variables for mode (use 'bike' as reference)\n",
    "long_df = pd.get_dummies(long_df, columns=['mode'], drop_first=False)\n",
    "if 'mode_bike' in long_df.columns:\n",
    "    long_df = long_df.drop(columns=['mode_bike'])  # reference category\n",
    "\n",
    "# Step 6: Define features (X) and target (y)\n",
    "X = long_df[['time', 'cost', 'risk', 'mode_bus', 'mode_car']]\n",
    "y = long_df['chosen']\n",
    "\n",
    "# Add constant (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Step 7: Ensure numeric types and remove missing values\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "data = pd.concat([X, y], axis=1).dropna()\n",
    "X = data.drop(columns=[y.name])\n",
    "y = data[y.name]\n",
    "\n",
    "# Step 8: Fit Multinomial Logit model using MLE\n",
    "model = sm.MNLogit(y, X)\n",
    "result = model.fit(method='newton', maxiter=100, disp=True)\n",
    "\n",
    "# Step 9: Output results\n",
    "print(\"\\nüìä Model Summary:\")\n",
    "print(result.summary())\n",
    "\n",
    "print(\"\\nüîÅ Odds Ratios (exp(coefficients)):\")\n",
    "print(np.exp(result.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. estimated parameter values from the preceding question and estimate the probability that an ‚Äúaverage‚Äù commuter (i.e., one whose values of ‚Äútime‚Äù, ‚Äúcost‚Äù, and ‚Äúrisk‚Äù are equal to the sample mean for each variable) would choose each mode of transportation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üö∂‚Äç‚ôÇÔ∏è Predicted Probabilities for Average Commuter:\n",
      "Bike: 0.0000\n",
      "Bus: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Predict probabilities for the average commuter\n",
    "\n",
    "# Compute average values of the covariates across all rows\n",
    "avg_time = long_df['time'].mean()\n",
    "avg_cost = long_df['cost'].mean()\n",
    "avg_risk = long_df['risk'].mean()\n",
    "\n",
    "# Create input rows for each mode (bike, bus, car)\n",
    "# Remember: we used dummy vars and dropped bike as reference\n",
    "# So bike: mode_bus = 0, mode_car = 0\n",
    "# bus:     mode_bus = 1, mode_car = 0\n",
    "# car:     mode_bus = 0, mode_car = 1\n",
    "\n",
    "avg_bike = [1, avg_time, avg_cost, avg_risk, 0, 0]\n",
    "avg_bus  = [1, avg_time, avg_cost, avg_risk, 1, 0]\n",
    "avg_car  = [1, avg_time, avg_cost, avg_risk, 0, 1]\n",
    "\n",
    "# Stack into a DataFrame\n",
    "avg_X = pd.DataFrame([avg_bike, avg_bus, avg_car],\n",
    "                     columns=['const', 'time', 'cost', 'risk', 'mode_bus', 'mode_car'],\n",
    "                     index=['Bike', 'Bus', 'Car'])\n",
    "\n",
    "# Use fitted model to predict probabilities\n",
    "probs = result.predict(avg_X)\n",
    "\n",
    "# Display result\n",
    "print(\"\\nüö∂‚Äç‚ôÇÔ∏è Predicted Probabilities for Average Commuter:\")\n",
    "for mode, prob in zip(avg_X.index, probs):\n",
    "    print(f\"{mode}: {prob:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
